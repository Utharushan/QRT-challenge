{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cab1586",
   "metadata": {},
   "source": [
    "# Construction d'un modèle de survie par stacking\n",
    "\n",
    "Ce notebook présente la construction d'un modèle de prédiction de survie utilisant une approche de stacking (empilement) combinant plusieurs algorithmes d'apprentissage automatique.\n",
    "\n",
    "## Objectif\n",
    "\n",
    "Prédire la survie de patients en utilisant des données cliniques et moléculaires, en combinant des modèles basés sur les arbres (Random Forest) et le boosting (XGBoost) via une approche de méta-apprentissage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101732d0",
   "metadata": {},
   "source": [
    "## 1. Chargement et préparation des données\n",
    "\n",
    "Nous commençons par charger et fusionner les données cliniques et moléculaires via la clé ID. Les variables cliniques (centre, compte de blastes, numérations sanguines, profil cytogénétique) sont imputées par la médiane lorsque nécessaire, puis certaines d'entre elles sont transformées (p. ex. log sur WBC, ANC pour réduire l'asymétrie)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1bcb692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Données cliniques: (3323, 9)\n",
      "Données moléculaires: (10935, 11)\n",
      "Données cibles: (3323, 3)\n",
      "\n",
      "Aperçu des données cliniques:\n",
      "        ID CENTER  BM_BLAST    WBC  ANC  MONOCYTES    HB    PLT  \\\n",
      "0  P132697    MSK      14.0    2.8  0.2        0.7   7.6  119.0   \n",
      "1  P132698    MSK       1.0    7.4  2.4        0.1  11.6   42.0   \n",
      "2  P116889    MSK      15.0    3.7  2.1        0.1  14.2   81.0   \n",
      "3  P132699    MSK       1.0    3.9  1.9        0.1   8.9   77.0   \n",
      "4  P132700    MSK       6.0  128.0  9.7        0.9  11.1  195.0   \n",
      "\n",
      "                          CYTOGENETICS  \n",
      "0      46,xy,del(20)(q12)[2]/46,xy[18]  \n",
      "1                                46,xx  \n",
      "2   46,xy,t(3;3)(q25;q27)[8]/46,xy[12]  \n",
      "3    46,xy,del(3)(q26q27)[15]/46,xy[5]  \n",
      "4  46,xx,t(3;9)(p13;q22)[10]/46,xx[10]  \n",
      "\n",
      "Aperçu des données moléculaires:\n",
      "        ID CHR        START          END                REF ALT    GENE  \\\n",
      "0  P100000  11  119149248.0  119149248.0                  G   A     CBL   \n",
      "1  P100000   5  131822301.0  131822301.0                  G   T    IRF1   \n",
      "2  P100000   3   77694060.0   77694060.0                  G   C   ROBO2   \n",
      "3  P100000   4  106164917.0  106164917.0                  G   T    TET2   \n",
      "4  P100000   2   25468147.0   25468163.0  ACGAAGAGGGGGTGTTC   A  DNMT3A   \n",
      "\n",
      "  PROTEIN_CHANGE                EFFECT     VAF   DEPTH  \n",
      "0        p.C419Y  non_synonymous_codon  0.0830  1308.0  \n",
      "1        p.Y164*           stop_gained  0.0220   532.0  \n",
      "2            p.?   splice_site_variant  0.4100   876.0  \n",
      "3       p.R1262L  non_synonymous_codon  0.4300   826.0  \n",
      "4   p.E505fs*141    frameshift_variant  0.0898   942.0  \n",
      "\n",
      "Aperçu des données cibles:\n",
      "        ID  OS_YEARS  OS_STATUS\n",
      "0  P132697  1.115068        1.0\n",
      "1  P132698  4.928767        0.0\n",
      "2  P116889  2.043836        0.0\n",
      "3  P132699  2.476712        1.0\n",
      "4  P132700  3.145205        0.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile\n",
    "\n",
    "# Chargement des données cliniques et moléculaires\n",
    "clin = pd.read_csv('X_train/clinical_train.csv')\n",
    "mol = pd.read_csv('X_train/molecular_train.csv')\n",
    "target = pd.read_csv('target_train.csv')\n",
    "\n",
    "print(f\"Données cliniques: {clin.shape}\")\n",
    "print(f\"Données moléculaires: {mol.shape}\")\n",
    "print(f\"Données cibles: {target.shape}\")\n",
    "\n",
    "# Aperçu des données\n",
    "print(\"\\nAperçu des données cliniques:\")\n",
    "print(clin.head())\n",
    "print(\"\\nAperçu des données moléculaires:\")\n",
    "print(mol.head())\n",
    "print(\"\\nAperçu des données cibles:\")\n",
    "print(target.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d8e20c",
   "metadata": {},
   "source": [
    "### Prétraitement des données cliniques\n",
    "\n",
    "Imputation des valeurs manquantes par la médiane pour les variables continues et transformations logarithmiques pour réduire l'asymétrie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "218b0f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables numériques après imputation et transformation:\n",
      "          BM_BLAST          WBC          ANC    MONOCYTES           HB  \\\n",
      "count  3323.000000  3323.000000  3323.000000  3323.000000  3323.000000   \n",
      "mean      5.884713     1.721027     1.169592     0.849908     9.887142   \n",
      "std       7.508283     0.614101     0.635635     2.423767     2.007378   \n",
      "min       0.000000     0.182322     0.000000     0.000000     4.000000   \n",
      "25%       1.300000     1.335001     0.693147     0.200000     8.600000   \n",
      "50%       3.000000     1.629241     1.098612     0.370000     9.700000   \n",
      "75%       8.000000     1.989925     1.508512     0.610000    11.100000   \n",
      "max      91.000000     5.046002     4.706101    44.200000    16.600000   \n",
      "\n",
      "               PLT  \n",
      "count  3323.000000  \n",
      "mean    165.405185  \n",
      "std     146.898251  \n",
      "min       2.000000  \n",
      "25%      67.000000  \n",
      "50%     123.000000  \n",
      "75%     223.500000  \n",
      "max    1451.000000  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\uthar\\AppData\\Local\\Temp\\ipykernel_19288\\1288892166.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  clin[c].fillna(clin[c].median(), inplace=True)\n",
      "C:\\Users\\uthar\\AppData\\Local\\Temp\\ipykernel_19288\\1288892166.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  clin[c].fillna(clin[c].median(), inplace=True)\n",
      "C:\\Users\\uthar\\AppData\\Local\\Temp\\ipykernel_19288\\1288892166.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  clin[c].fillna(clin[c].median(), inplace=True)\n",
      "C:\\Users\\uthar\\AppData\\Local\\Temp\\ipykernel_19288\\1288892166.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  clin[c].fillna(clin[c].median(), inplace=True)\n",
      "C:\\Users\\uthar\\AppData\\Local\\Temp\\ipykernel_19288\\1288892166.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  clin[c].fillna(clin[c].median(), inplace=True)\n",
      "C:\\Users\\uthar\\AppData\\Local\\Temp\\ipykernel_19288\\1288892166.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  clin[c].fillna(clin[c].median(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Imputation des manquants par la médiane pour les variables continues\n",
    "num_cols = ['BM_BLAST','WBC','ANC','MONOCYTES','HB','PLT']\n",
    "for c in num_cols:\n",
    "    clin[c] = pd.to_numeric(clin[c], errors='coerce')\n",
    "    clin[c].fillna(clin[c].median(), inplace=True)\n",
    "\n",
    "# Transformation (log) pour WBC et ANC pour réduire l'asymétrie\n",
    "clin['WBC'] = np.log1p(clin['WBC'])\n",
    "clin['ANC'] = np.log1p(clin['ANC'])\n",
    "\n",
    "print(\"Variables numériques après imputation et transformation:\")\n",
    "print(clin[num_cols].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b787aad",
   "metadata": {},
   "source": [
    "### Extraction des caractéristiques cytogénétiques\n",
    "\n",
    "Nous extrayons des caractéristiques cytogénétiques simples : indicateur de caryotype normal (si la chaîne commence par « 46,xx » ou « 46,xy » sans anomalies déclarées), et la présence d'anomalies connues (monosomie 7, gain de chromosome 8). Ces nouvelles variables binaires sont ajoutées aux données cliniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3419ca32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caractéristiques cytogénétiques créées:\n",
      "Caryotype normal: 1693 patients\n",
      "Monosomie 7: 169 patients\n",
      "Gain chromosome 8: 230 patients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:12: SyntaxWarning: invalid escape sequence '\\+'\n",
      "<>:12: SyntaxWarning: invalid escape sequence '\\+'\n",
      "C:\\Users\\uthar\\AppData\\Local\\Temp\\ipykernel_19288\\20959312.py:12: SyntaxWarning: invalid escape sequence '\\+'\n",
      "  clin['cyto_gain8'] = clin['CYTOGENETICS'].fillna('').str.contains('\\+8').astype(int)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Fonction pour détecter un caryotype normal (46,xx ou 46,xy pur)\n",
    "def is_normal_karyotype(s):\n",
    "    if pd.isna(s): \n",
    "        return False\n",
    "    return bool(re.match(r'46,(xx|xy)(\\[|$)', s.strip()))\n",
    "    \n",
    "# Extraction des caractéristiques cytogénétiques\n",
    "clin['cyto_normal'] = clin['CYTOGENETICS'].apply(is_normal_karyotype).astype(int)\n",
    "clin['cyto_mono7'] = clin['CYTOGENETICS'].fillna('').str.contains('-7').astype(int)\n",
    "clin['cyto_gain8'] = clin['CYTOGENETICS'].fillna('').str.contains('\\+8').astype(int)\n",
    "\n",
    "print(\"Caractéristiques cytogénétiques créées:\")\n",
    "print(f\"Caryotype normal: {clin['cyto_normal'].sum()} patients\")\n",
    "print(f\"Monosomie 7: {clin['cyto_mono7'].sum()} patients\")\n",
    "print(f\"Gain chromosome 8: {clin['cyto_gain8'].sum()} patients\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8e2c91",
   "metadata": {},
   "source": [
    "### Encodage du centre de traitement\n",
    "\n",
    "Encodage one-hot du centre de traitement pour capturer les effets de centres différents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bd49967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de centres encodés: 23\n",
      "Forme finale des données cliniques: (3323, 33)\n"
     ]
    }
   ],
   "source": [
    "# One-hot encoding du centre de traitement\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ctr_ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "ctr_feat = ctr_ohe.fit_transform(clin[['CENTER']])\n",
    "ctr_df = pd.DataFrame(ctr_feat, columns=ctr_ohe.get_feature_names_out(['CENTER']))\n",
    "\n",
    "# Concaténation avec les données cliniques\n",
    "clin = pd.concat([clin.reset_index(drop=True), ctr_df], axis=1)\n",
    "clin.drop(['CENTER','CYTOGENETICS'], axis=1, inplace=True)\n",
    "\n",
    "print(f\"Nombre de centres encodés: {ctr_feat.shape[1]}\")\n",
    "print(f\"Forme finale des données cliniques: {clin.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e76c59e",
   "metadata": {},
   "source": [
    "## 2. Ingénierie des variables moléculaires\n",
    "\n",
    "Chaque patient possède plusieurs mutations listées dans le fichier moléculaire. Nous agrégeons cette information par patient (ID) pour extraire des variables globales :\n",
    "- **Nmut** : nombre total de mutations\n",
    "- **Nstrong** : nombre de mutations « à fort impact » (frameshift, stop-gain, splice-site)\n",
    "- **VAF_mean** et **VAF_max** : statistiques sur la Fraction Allélique (VAF)\n",
    "- **Indicateurs de gènes** : présence de mutations dans les gènes fréquemment altérés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a4ccf7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agrégats moléculaires calculés:\n",
      "Nmut - Mutations totales par patient: count    3026.000000\n",
      "mean        3.613681\n",
      "std         2.220222\n",
      "min         1.000000\n",
      "25%         2.000000\n",
      "50%         3.000000\n",
      "75%         5.000000\n",
      "max        17.000000\n",
      "Name: Nmut, dtype: float64\n",
      "Nstrong - Mutations à fort impact: count    3026.000000\n",
      "mean        1.672835\n",
      "std         1.571451\n",
      "min         0.000000\n",
      "25%         1.000000\n",
      "50%         1.000000\n",
      "75%         2.000000\n",
      "max        12.000000\n",
      "Name: Nstrong, dtype: float64\n",
      "VAF_mean - VAF moyen: count    3024.000000\n",
      "mean        0.307040\n",
      "std         0.159688\n",
      "min         0.020000\n",
      "25%         0.192500\n",
      "50%         0.297000\n",
      "75%         0.410775\n",
      "max         0.989000\n",
      "Name: VAF_mean, dtype: float64\n",
      "VAF_max - VAF maximum: count    3024.000000\n",
      "mean        0.445481\n",
      "std         0.229083\n",
      "min         0.020000\n",
      "25%         0.305900\n",
      "50%         0.442000\n",
      "75%         0.509250\n",
      "max         0.999000\n",
      "Name: VAF_max, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calcul des agrégats par patient\n",
    "mol['VAF'] = pd.to_numeric(mol['VAF'], errors='coerce')\n",
    "\n",
    "# Nombre total de mutations par patient\n",
    "Nmut = mol.groupby('ID').size().rename('Nmut')\n",
    "\n",
    "# Compter les mutations à fort impact\n",
    "strong_impacts = ['stop_gained','frameshift_variant','splice_site_variant']\n",
    "mol['strong'] = mol['EFFECT'].isin(strong_impacts).astype(int)\n",
    "Nstrong = mol.groupby('ID')['strong'].sum().rename('Nstrong')\n",
    "\n",
    "# Statistiques de VAF\n",
    "VAF_mean = mol.groupby('ID')['VAF'].mean().rename('VAF_mean')\n",
    "VAF_max = mol.groupby('ID')['VAF'].max().rename('VAF_max')\n",
    "\n",
    "print(\"Agrégats moléculaires calculés:\")\n",
    "print(f\"Nmut - Mutations totales par patient: {Nmut.describe()}\")\n",
    "print(f\"Nstrong - Mutations à fort impact: {Nstrong.describe()}\")\n",
    "print(f\"VAF_mean - VAF moyen: {VAF_mean.describe()}\")\n",
    "print(f\"VAF_max - VAF maximum: {VAF_max.describe()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c903ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indicateurs de gènes créés:\n",
      "TET2: 1033 patients avec mutation\n",
      "ASXL1: 893 patients avec mutation\n",
      "SF3B1: 739 patients avec mutation\n",
      "DNMT3A: 534 patients avec mutation\n",
      "RUNX1: 462 patients avec mutation\n",
      "SRSF2: 571 patients avec mutation\n",
      "TP53: 379 patients avec mutation\n",
      "STAG2: 301 patients avec mutation\n",
      "U2AF1: 285 patients avec mutation\n",
      "EZH2: 216 patients avec mutation\n",
      "\n",
      "Forme des caractéristiques moléculaires: (3026, 14)\n"
     ]
    }
   ],
   "source": [
    "# Indicateurs de présence pour les gènes clés (top 10 gènes les plus mutants)\n",
    "top_genes = ['TET2','ASXL1','SF3B1','DNMT3A','RUNX1','SRSF2','TP53','STAG2','U2AF1','EZH2']\n",
    "\n",
    "for gene in top_genes:\n",
    "    mol[gene] = (mol['GENE'] == gene).astype(int)\n",
    "\n",
    "gene_features = mol.groupby('ID')[top_genes].max()\n",
    "\n",
    "print(\"Indicateurs de gènes créés:\")\n",
    "for gene in top_genes:\n",
    "    count = gene_features[gene].sum()\n",
    "    print(f\"{gene}: {count} patients avec mutation\")\n",
    "\n",
    "# Fusion de toutes les variables moléculaires\n",
    "mol_feat = pd.concat([Nmut, Nstrong, VAF_mean, VAF_max, gene_features], axis=1).fillna(0)\n",
    "\n",
    "print(f\"\\nForme des caractéristiques moléculaires: {mol_feat.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c1bc62",
   "metadata": {},
   "source": [
    "### Fusion des données cliniques et moléculaires\n",
    "\n",
    "Jointure des données cliniques prétraitées avec les caractéristiques moléculaires agrégées pour former la matrice finale d'entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ab5b149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice finale d'entraînement: (3173, 46)\n",
      "Variable cible (OS_YEARS): 3173 échantillons\n",
      "Statistiques de survie: min=0.00, max=22.04, moyenne=2.48\n"
     ]
    }
   ],
   "source": [
    "# Préparation des données pour la jointure (ID en index)\n",
    "X_clin = clin.set_index('ID')\n",
    "X_mol = mol_feat\n",
    "\n",
    "# Jointure des données cliniques et moléculaires\n",
    "X_all = X_clin.join(X_mol, how='left').fillna(0)\n",
    "\n",
    "# Préparation de la cible d'entraînement (enlever les cas sans données d'OS)\n",
    "y = target.dropna().set_index('ID')\n",
    "X_all = X_all.loc[y.index]\n",
    "y_years = y['OS_YEARS'].values\n",
    "\n",
    "print(f\"Matrice finale d'entraînement: {X_all.shape}\")\n",
    "print(f\"Variable cible (OS_YEARS): {len(y_years)} échantillons\")\n",
    "print(f\"Statistiques de survie: min={y_years.min():.2f}, max={y_years.max():.2f}, moyenne={y_years.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6b3691",
   "metadata": {},
   "source": [
    "## 3. Modèles prédictifs\n",
    "\n",
    "Nous entraînons plusieurs modèles de survie pour capter différents aspects des données :\n",
    "\n",
    "1. **XGBoost** : modèle de boosting pour capturer les interactions complexes\n",
    "2. **Random Forest** : modèle basé sur les arbres, robuste et stable\n",
    "3. **Stacking** : méta-modèle combinant les prédictions des modèles de base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28daa27c",
   "metadata": {},
   "source": [
    "### Entraînement des modèles de base\n",
    "\n",
    "Des modèles basés sur les arbres (Random Forest) et le boosting (XGBoost) pour prédire le temps de survie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3dce127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entraînement du modèle XGBoost...\n",
      "Entraînement du modèle Random Forest...\n",
      "\n",
      "Performances (CV MSE):\n",
      "XGBoost: 7.3744 (+/- 6.0230)\n",
      "Random Forest: 7.0060 (+/- 5.2441)\n",
      "\n",
      "Modèles de base entraînés avec succès!\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Modèle XGBoost (régression sur OS_YEARS)\n",
    "print(\"Entraînement du modèle XGBoost...\")\n",
    "xgb_model = XGBRegressor(\n",
    "    objective='reg:squarederror', \n",
    "    n_estimators=200, \n",
    "    random_state=0,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=6\n",
    ")\n",
    "xgb_model.fit(X_all, y_years)\n",
    "\n",
    "# Forêt aléatoire (RandomForestRegressor) sur OS_YEARS\n",
    "print(\"Entraînement du modèle Random Forest...\")\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=200, \n",
    "    random_state=0,\n",
    "    max_depth=10,\n",
    "    min_samples_split=5\n",
    ")\n",
    "rf_model.fit(X_all, y_years)\n",
    "\n",
    "# Évaluation des modèles par validation croisée\n",
    "xgb_scores = cross_val_score(xgb_model, X_all, y_years, cv=5, scoring='neg_mean_squared_error')\n",
    "rf_scores = cross_val_score(rf_model, X_all, y_years, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "print(f\"\\nPerformances (CV MSE):\")\n",
    "print(f\"XGBoost: {-xgb_scores.mean():.4f} (+/- {xgb_scores.std() * 2:.4f})\")\n",
    "print(f\"Random Forest: {-rf_scores.mean():.4f} (+/- {rf_scores.std() * 2:.4f})\")\n",
    "\n",
    "print(\"\\nModèles de base entraînés avec succès!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32e593f",
   "metadata": {},
   "source": [
    "### Stacking (Empilement) des modèles\n",
    "\n",
    "Le principe du stacking est d'entraîner plusieurs modèles de base différents et d'utiliser leurs prédictions comme entrées d'un méta-modèle qui apprendra à les combiner optimalement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2150b2a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Génération des prédictions pour le stacking...\n",
      "Matrice de stacking: (3173, 2)\n",
      "Corrélation entre les prédictions: 0.9242\n",
      "Entraînement du méta-modèle...\n",
      "\n",
      "Performances du modèle stacké:\n",
      "MSE: 0.7754\n",
      "RMSE: 0.8806\n",
      "\n",
      "Coefficients du méta-modèle:\n",
      "XGBoost: 1.4421\n",
      "Random Forest: -0.2321\n",
      "Intercept: -0.5123\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Prédictions des modèles de base sur l'ensemble d'entraînement\n",
    "print(\"Génération des prédictions pour le stacking...\")\n",
    "pred_xgb = xgb_model.predict(X_all)\n",
    "pred_rf = rf_model.predict(X_all)\n",
    "\n",
    "# Création de la matrice d'empilage (stacking matrix)\n",
    "stack_X = np.vstack([pred_xgb, pred_rf]).T\n",
    "\n",
    "print(f\"Matrice de stacking: {stack_X.shape}\")\n",
    "print(f\"Corrélation entre les prédictions: {np.corrcoef(pred_xgb, pred_rf)[0,1]:.4f}\")\n",
    "\n",
    "# Méta-modèle linéaire sur les prédictions empilées\n",
    "print(\"Entraînement du méta-modèle...\")\n",
    "meta_model = LinearRegression().fit(stack_X, y_years)\n",
    "\n",
    "# Prédiction finale avec le modèle stacké\n",
    "final_pred = meta_model.predict(stack_X)\n",
    "final_mse = mean_squared_error(y_years, final_pred)\n",
    "\n",
    "print(f\"\\nPerformances du modèle stacké:\")\n",
    "print(f\"MSE: {final_mse:.4f}\")\n",
    "print(f\"RMSE: {np.sqrt(final_mse):.4f}\")\n",
    "\n",
    "# Coefficients du méta-modèle\n",
    "print(f\"\\nCoefficients du méta-modèle:\")\n",
    "print(f\"XGBoost: {meta_model.coef_[0]:.4f}\")\n",
    "print(f\"Random Forest: {meta_model.coef_[1]:.4f}\")\n",
    "print(f\"Intercept: {meta_model.intercept_:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136dd95b",
   "metadata": {},
   "source": [
    "## 4. Prédictions finales et soumission\n",
    "\n",
    "Application du pipeline complet au jeu de test pour générer les scores de risque. Le score de risque est défini comme l'opposé du temps de survie prédit (plus le score est élevé, plus le risque de décès est grand)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f23f41",
   "metadata": {},
   "source": [
    "### Préparation des données de test\n",
    "\n",
    "Application des mêmes étapes de prétraitement aux données de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac253749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement des données de test...\n",
      "Données cliniques test: (1193, 9)\n",
      "Données moléculaires test: (3089, 11)\n",
      "Prétraitement des données cliniques de test...\n",
      "Prétraitement des données cliniques de test terminé.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:26: SyntaxWarning: invalid escape sequence '\\+'\n",
      "<>:26: SyntaxWarning: invalid escape sequence '\\+'\n",
      "C:\\Users\\uthar\\AppData\\Local\\Temp\\ipykernel_19288\\4286984736.py:26: SyntaxWarning: invalid escape sequence '\\+'\n",
      "  clin_test['cyto_gain8'] = clin_test['CYTOGENETICS'].fillna('').str.contains('\\+8').astype(int)\n",
      "C:\\Users\\uthar\\AppData\\Local\\Temp\\ipykernel_19288\\4286984736.py:17: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  clin_test[c].fillna(train_median, inplace=True)\n",
      "C:\\Users\\uthar\\AppData\\Local\\Temp\\ipykernel_19288\\4286984736.py:17: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  clin_test[c].fillna(train_median, inplace=True)\n",
      "C:\\Users\\uthar\\AppData\\Local\\Temp\\ipykernel_19288\\4286984736.py:17: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  clin_test[c].fillna(train_median, inplace=True)\n",
      "C:\\Users\\uthar\\AppData\\Local\\Temp\\ipykernel_19288\\4286984736.py:17: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  clin_test[c].fillna(train_median, inplace=True)\n",
      "C:\\Users\\uthar\\AppData\\Local\\Temp\\ipykernel_19288\\4286984736.py:17: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  clin_test[c].fillna(train_median, inplace=True)\n",
      "C:\\Users\\uthar\\AppData\\Local\\Temp\\ipykernel_19288\\4286984736.py:17: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  clin_test[c].fillna(train_median, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Chargement des données de test\n",
    "print(\"Chargement des données de test...\")\n",
    "clin_test = pd.read_csv('X_test/clinical_test.csv')\n",
    "mol_test = pd.read_csv('X_test/molecular_test.csv')\n",
    "\n",
    "print(f\"Données cliniques test: {clin_test.shape}\")\n",
    "print(f\"Données moléculaires test: {mol_test.shape}\")\n",
    "\n",
    "# Application du même prétraitement aux données cliniques de test\n",
    "print(\"Prétraitement des données cliniques de test...\")\n",
    "\n",
    "# Imputation par la médiane (utiliser les mêmes valeurs que l'entraînement)\n",
    "for c in num_cols:\n",
    "    clin_test[c] = pd.to_numeric(clin_test[c], errors='coerce')\n",
    "    # Utiliser la médiane de l'entraînement pour l'imputation\n",
    "    train_median = clin[c].median() if c in ['BM_BLAST','MONOCYTES','HB','PLT'] else clin[c].median()\n",
    "    clin_test[c].fillna(train_median, inplace=True)\n",
    "\n",
    "# Transformations logarithmiques\n",
    "clin_test['WBC'] = np.log1p(clin_test['WBC'])\n",
    "clin_test['ANC'] = np.log1p(clin_test['ANC'])\n",
    "\n",
    "# Caractéristiques cytogénétiques\n",
    "clin_test['cyto_normal'] = clin_test['CYTOGENETICS'].apply(is_normal_karyotype).astype(int)\n",
    "clin_test['cyto_mono7'] = clin_test['CYTOGENETICS'].fillna('').str.contains('-7').astype(int)\n",
    "clin_test['cyto_gain8'] = clin_test['CYTOGENETICS'].fillna('').str.contains('\\+8').astype(int)\n",
    "\n",
    "# Encodage des centres (utiliser le même encodeur)\n",
    "ctr_feat_test = ctr_ohe.transform(clin_test[['CENTER']])\n",
    "ctr_df_test = pd.DataFrame(ctr_feat_test, columns=ctr_ohe.get_feature_names_out(['CENTER']))\n",
    "clin_test = pd.concat([clin_test.reset_index(drop=True), ctr_df_test], axis=1)\n",
    "clin_test.drop(['CENTER','CYTOGENETICS'], axis=1, inplace=True)\n",
    "\n",
    "print(\"Prétraitement des données cliniques de test terminé.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "469f5bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prétraitement des données moléculaires de test...\n",
      "Matrice finale de test: (1193, 46)\n",
      "Matrice de test finale: (1193, 46)\n",
      "Prétraitement des données de test terminé.\n"
     ]
    }
   ],
   "source": [
    "# Prétraitement des données moléculaires de test\n",
    "print(\"Prétraitement des données moléculaires de test...\")\n",
    "\n",
    "# Calcul des agrégats pour le test\n",
    "mol_test['VAF'] = pd.to_numeric(mol_test['VAF'], errors='coerce')\n",
    "Nmut_test = mol_test.groupby('ID').size().rename('Nmut')\n",
    "\n",
    "# Mutations à fort impact\n",
    "mol_test['strong'] = mol_test['EFFECT'].isin(strong_impacts).astype(int)\n",
    "Nstrong_test = mol_test.groupby('ID')['strong'].sum().rename('Nstrong')\n",
    "\n",
    "# Statistiques VAF\n",
    "VAF_mean_test = mol_test.groupby('ID')['VAF'].mean().rename('VAF_mean')\n",
    "VAF_max_test = mol_test.groupby('ID')['VAF'].max().rename('VAF_max')\n",
    "\n",
    "# Indicateurs de gènes\n",
    "for gene in top_genes:\n",
    "    mol_test[gene] = (mol_test['GENE'] == gene).astype(int)\n",
    "gene_features_test = mol_test.groupby('ID')[top_genes].max()\n",
    "\n",
    "# Fusion des caractéristiques moléculaires\n",
    "mol_feat_test = pd.concat([Nmut_test, Nstrong_test, VAF_mean_test, VAF_max_test, gene_features_test], axis=1).fillna(0)\n",
    "\n",
    "# Jointure finale des données de test\n",
    "X_clin_test = clin_test.set_index('ID')\n",
    "X_test = X_clin_test.join(mol_feat_test, how='left').fillna(0)\n",
    "\n",
    "print(f\"Matrice finale de test: {X_test.shape}\")\n",
    "\n",
    "# S'assurer que les colonnes correspondent à celles de l'entraînement\n",
    "missing_cols = set(X_all.columns) - set(X_test.columns)\n",
    "extra_cols = set(X_test.columns) - set(X_all.columns)\n",
    "\n",
    "if missing_cols:\n",
    "    print(f\"Colonnes manquantes dans le test: {missing_cols}\")\n",
    "    for col in missing_cols:\n",
    "        X_test[col] = 0\n",
    "\n",
    "if extra_cols:\n",
    "    print(f\"Colonnes supplémentaires dans le test: {extra_cols}\")\n",
    "    X_test = X_test.drop(columns=list(extra_cols))\n",
    "\n",
    "# Réordonner les colonnes pour qu'elles correspondent\n",
    "X_test = X_test[X_all.columns]\n",
    "\n",
    "print(f\"Matrice de test finale: {X_test.shape}\")\n",
    "print(\"Prétraitement des données de test terminé.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2dbe5c8",
   "metadata": {},
   "source": [
    "### Génération des prédictions finales\n",
    "\n",
    "Application du modèle stacké aux données de test pour générer les scores de risque."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7836809f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Génération des prédictions finales...\n",
      "Prédictions générées pour 1193 patients de test\n",
      "Statistiques des scores de risque:\n",
      "  Min: -8.5372\n",
      "  Max: 1.6591\n",
      "  Moyenne: -1.4857\n",
      "  Médiane: -1.2336\n",
      "\n",
      "Fichier de soumission généré: y_test.csv\n",
      "Nombre de prédictions: 1193\n",
      "\n",
      "Aperçu du fichier de soumission:\n",
      "      ID  risk_score\n",
      "0   KYW1   -0.621691\n",
      "1   KYW2   -0.777121\n",
      "2   KYW3   -1.748210\n",
      "3   KYW4   -0.186051\n",
      "4   KYW5   -0.962737\n",
      "5   KYW6   -0.329525\n",
      "6   KYW7   -0.850392\n",
      "7   KYW8   -1.636858\n",
      "8   KYW9   -1.709925\n",
      "9  KYW10   -2.288068\n"
     ]
    }
   ],
   "source": [
    "# Prédictions des modèles de base sur les données de test\n",
    "print(\"Génération des prédictions finales...\")\n",
    "\n",
    "pred_test_xgb = xgb_model.predict(X_test)\n",
    "pred_test_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Création de la matrice de stacking pour le test\n",
    "stack_test = np.vstack([pred_test_xgb, pred_test_rf]).T\n",
    "\n",
    "# Prédiction finale avec le méta-modèle\n",
    "pred_test_years = meta_model.predict(stack_test)\n",
    "\n",
    "# Conversion en scores de risque (plus grand = plus de risque)\n",
    "risk_score = -pred_test_years\n",
    "\n",
    "print(f\"Prédictions générées pour {len(risk_score)} patients de test\")\n",
    "print(f\"Statistiques des scores de risque:\")\n",
    "print(f\"  Min: {risk_score.min():.4f}\")\n",
    "print(f\"  Max: {risk_score.max():.4f}\")\n",
    "print(f\"  Moyenne: {risk_score.mean():.4f}\")\n",
    "print(f\"  Médiane: {np.median(risk_score):.4f}\")\n",
    "\n",
    "# Génération du fichier de soumission\n",
    "submission = pd.DataFrame({\n",
    "    'ID': X_test.index, \n",
    "    'risk_score': risk_score\n",
    "})\n",
    "\n",
    "# Sauvegarde du fichier de soumission\n",
    "submission_filename = 'y_test.csv'\n",
    "submission.to_csv(submission_filename, index=False)\n",
    "\n",
    "print(f\"\\nFichier de soumission généré: {submission_filename}\")\n",
    "print(f\"Nombre de prédictions: {len(submission)}\")\n",
    "print(\"\\nAperçu du fichier de soumission:\")\n",
    "print(submission.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e9d82d",
   "metadata": {},
   "source": [
    "## 5. Résumé et conclusion\n",
    "\n",
    "### Approche utilisée\n",
    "\n",
    "Nous avons construit un modèle de survie combinant plusieurs techniques d'apprentissage automatique :\n",
    "\n",
    "1. **Prétraitement des données** :\n",
    "   - Imputation des valeurs manquantes par la médiane\n",
    "   - Transformations logarithmiques pour réduire l'asymétrie\n",
    "   - Extraction de caractéristiques cytogénétiques binaires\n",
    "   - Encodage one-hot des centres de traitement\n",
    "   - Agrégation des données moléculaires par patient\n",
    "\n",
    "2. **Modèles de base** :\n",
    "   - **XGBoost** : pour capturer les interactions complexes et non-linéaires\n",
    "   - **Random Forest** : pour la robustesse et la stabilité des prédictions\n",
    "\n",
    "3. **Stacking (Empilement)** :\n",
    "   - Méta-modèle linéaire combinant les prédictions des modèles de base\n",
    "   - Optimise le score de concordance en fusionnant les perspectives complémentaires\n",
    "\n",
    "### Avantages de cette approche\n",
    "\n",
    "- **Robustesse** : Les Random Forests sont réputées robustes pour la survie\n",
    "- **Flexibilité** : XGBoost capture les interactions complexes\n",
    "- **Amélioration** : Le stacking combine les forces de chaque modèle\n",
    "- **Généralisation** : L'ensemble réduit le sur-apprentissage\n",
    "\n",
    "### Sources et références\n",
    "\n",
    "- **Random Survival Forests** : Extension des forêts aléatoires à la censure (scikit-survival)\n",
    "- **Stacking** : Technique de méta-apprentissage pour combiner plusieurs modèles\n",
    "- **XGBoost** : Algorithme de boosting efficace pour les problèmes de régression\n",
    "\n",
    "Cette approche d'ensemble permet de capturer à la fois les interactions complexes et d'augmenter la robustesse du pronostic pour optimiser le score de concordance final."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

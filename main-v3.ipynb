{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8f2b5bc",
   "metadata": {},
   "source": [
    "# Modèle de survie avancé pour prédiction du risque de décès\n",
    "\n",
    "Ce notebook améliore l'approche précédente en combinant plusieurs modèles de survie, une ingénierie de features avancée et une optimisation des hyperparamètres pour maximiser le score IPCW-C-index."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6347ee18",
   "metadata": {},
   "source": [
    "## 1. Chargement des données\n",
    "\n",
    "Chargement des données cliniques, moléculaires et cibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5730c434",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sksurv.ensemble import RandomSurvivalForest\n",
    "from sksurv.linear_model import CoxPHSurvivalAnalysis\n",
    "from sksurv.metrics import concordance_index_ipcw\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "clin = pd.read_csv('X_train/clinical_train.csv')\n",
    "mol = pd.read_csv('X_train/molecular_train.csv')\n",
    "target = pd.read_csv('target_train.csv')\n",
    "\n",
    "clin_test = pd.read_csv('X_test/clinical_test.csv')\n",
    "mol_test = pd.read_csv('X_test/molecular_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8a1e89",
   "metadata": {},
   "source": [
    "## 2. Ingénierie de features cliniques et moléculaires\n",
    "\n",
    "Imputation, transformation, extraction de variables binaires et agrégation moléculaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cca93302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputation et transformation des variables continues\n",
    "num_cols = ['BM_BLAST','WBC','ANC','MONOCYTES','HB','PLT']\n",
    "for df in [clin, clin_test]:\n",
    "    for c in num_cols:\n",
    "        df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "    df[num_cols] = SimpleImputer(strategy='median').fit_transform(df[num_cols])\n",
    "    df['WBC'] = np.log1p(df['WBC'])\n",
    "    df['ANC'] = np.log1p(df['ANC'])\n",
    "# Extraction de features cytogénétiques\n",
    "def is_normal_karyotype(s):\n",
    "    if pd.isna(s): return 0\n",
    "    return int(str(s).startswith('46,XX') or str(s).startswith('46,XY'))\n",
    "for df in [clin, clin_test]:\n",
    "    df['cyto_normal'] = df['CYTOGENETICS'].apply(is_normal_karyotype)\n",
    "    df['cyto_mono7'] = df['CYTOGENETICS'].fillna('').str.contains('-7').astype(int)\n",
    "    df['cyto_gain8'] = df['CYTOGENETICS'].fillna('').str.contains('\\+8').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aad9aad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encodage one-hot du centre\n",
    "ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "ctr_train = ohe.fit_transform(clin[['CENTER']])\n",
    "ctr_test = ohe.transform(clin_test[['CENTER']])\n",
    "ctr_train_df = pd.DataFrame(ctr_train, columns=ohe.get_feature_names_out(['CENTER']))\n",
    "ctr_test_df = pd.DataFrame(ctr_test, columns=ohe.get_feature_names_out(['CENTER']))\n",
    "clin = pd.concat([clin.reset_index(drop=True), ctr_train_df], axis=1)\n",
    "clin_test = pd.concat([clin_test.reset_index(drop=True), ctr_test_df], axis=1)\n",
    "clin.drop(['CENTER','CYTOGENETICS'], axis=1, inplace=True)\n",
    "clin_test.drop(['CENTER','CYTOGENETICS'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04720951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrégation moléculaire\n",
    "def aggregate_mol(mol_df):\n",
    "    mol_df['VAF'] = pd.to_numeric(mol_df['VAF'], errors='coerce')\n",
    "    strong_impacts = ['stop_gained','frameshift_variant','splice_site_variant']\n",
    "    mol_df['strong'] = mol_df['EFFECT'].isin(strong_impacts).astype(int)\n",
    "    top_genes = mol_df['GENE'].value_counts().index[:10].tolist()\n",
    "    for gene in top_genes:\n",
    "        mol_df[gene] = (mol_df['GENE'] == gene).astype(int)\n",
    "    agg = mol_df.groupby('ID').agg({\n",
    "        'VAF': ['mean','max'],\n",
    "        'strong': 'sum',\n",
    "        'GENE': 'count',\n",
    "        **{gene: ('max') for gene in top_genes}\n",
    "    })\n",
    "    agg.columns = ['VAF_mean','VAF_max','Nstrong','Nmut'] + [f'has_{g}' for g in top_genes]\n",
    "    return agg.fillna(0)\n",
    "mol_feat = aggregate_mol(mol)\n",
    "mol_feat_test = aggregate_mol(mol_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de42b01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fusion des données\n",
    "X_train = clin.set_index('ID').join(mol_feat, how='left').fillna(0)\n",
    "X_test = clin_test.set_index('ID').join(mol_feat_test, how='left').fillna(0)\n",
    "# Harmonisation des colonnes\n",
    "missing_cols = set(X_train.columns) - set(X_test.columns)\n",
    "for col in missing_cols:\n",
    "    X_test[col] = 0\n",
    "extra_cols = set(X_test.columns) - set(X_train.columns)\n",
    "X_test = X_test.drop(columns=list(extra_cols))\n",
    "X_test = X_test[X_train.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ee2dc0",
   "metadata": {},
   "source": [
    "## 3. Sélection de variables et réduction de dimension\n",
    "\n",
    "Standardisation et PCA pour réduire la dimensionnalité et améliorer la robustesse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c82021b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "pca = PCA(n_components=0.95, svd_solver='full')\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc408f4",
   "metadata": {},
   "source": [
    "## 4. Préparation de la cible et gestion de la censure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7bd779c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = target.dropna(subset=['OS_YEARS','OS_STATUS'])\n",
    "y_struct = np.array([(bool(s), t) for s, t in zip(target['OS_STATUS'], target['OS_YEARS'])], dtype=[('event', bool), ('time', float)])\n",
    "ids = target['ID'].values\n",
    "X_train_pca = X_train_pca[np.isin(X_train.index, ids)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e2df5f",
   "metadata": {},
   "source": [
    "## 5. Entraînement des modèles de survie avancés et stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2d001cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CoxPH\n",
    "cox = CoxPHSurvivalAnalysis()\n",
    "cox.fit(X_train_pca, y_struct)\n",
    "cox_pred = cox.predict(X_test_pca)\n",
    "# Random Survival Forest\n",
    "rsf = RandomSurvivalForest(n_estimators=200, min_samples_split=10, min_samples_leaf=5, max_features='sqrt', random_state=42)\n",
    "rsf.fit(X_train_pca, y_struct)\n",
    "rsf_pred = rsf.predict(X_test_pca)\n",
    "# Stacking (moyenne pondérée, peut être optimisée)\n",
    "risk_score = 0.6 * rsf_pred + 0.4 * cox_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07406e9f",
   "metadata": {},
   "source": [
    "## 6. Génération du fichier de soumission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2f2a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ID  risk_score\n",
      "0  KYW1  769.418935\n",
      "1  KYW2  549.230884\n",
      "2  KYW3  342.961620\n",
      "3  KYW4  703.309901\n",
      "4  KYW5  726.695382\n"
     ]
    }
   ],
   "source": [
    "submission = pd.DataFrame({'ID': X_test.index, 'risk_score': risk_score})\n",
    "submission.to_csv('y_test.csv', index=False)\n",
    "print(submission.head())\n",
    "\n",
    "# SCORE : 0.7364"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
